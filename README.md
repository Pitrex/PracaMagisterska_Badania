Klasyfikacja strumieni danych
Strumienie danych to uporządkowane sekwencje stale napływających danych o potencjalnie nieskończonej wielkości. Strumienie danych zazwyczaj cechują się dużą szybkością napływania danych i dużą zmiennością w czasie. W odróżnieniu od tradycyjnych bloków danych w przypadku strumieni danych istotnymi aspektami do uwzględnienia podczas projektowania algorytmów klasyfikacji są duże ograniczenia zasobów, konieczność gotowości do predykcji w każdym momencie oraz dryf koncepcji. Ograniczenia zasobów oraz konieczność predykcji wynikają bezpośrednio z faktu ciągłego, szybkiego napływu danych, często o dużej zmienności, natomiast dryf koncepcji jest zjawiskiem występującym w przypadku strumieni dynamicznych, w których wraz z upływem czasu rozkład przestrzeni cech napływających danych znacząco się zmienia powodując drastyczny spadek przydatności obecnie używanego klasyfikatora[1].
Strumienie danych można podzielić na strumienie stacjonarne, charakteryzujące się niezmiennością w czasie oraz dynamiczne, w których taka zmienność występuje i jest określana jako dryf koncepcji. Dryf koncepcji jest jednym z największych problemów występujących podczas klasyfikacji strumieni danych wykluczającym zastosowanie niektórych algorytmów występujących w tradycyjnym uczeniu nadzorowanym opartym na skończonej liczbie bloków danych[1]. Wśród zmian występujących w ramach dryfu koncepcji można wymienić zmiany nagłe, inkrementalne, gradualne i rekurencyjne[2]. W przypadku zmian nagłych dryf koncepcji jest często nazywany "zmianą koncepcji"(ang. concept shift), podczas gdy dla zmian postępujących stopniowo zostaje zachowana nazwa "dryfu koncepcji" (ang. concept drift)[3].
Podstawowym kryterium podziału metod klasyfikacji niestacjonarnych strumieni danych jest sposób przetwarzania badanego strumienia. Wśród występujących rozwiązań można wymienić podejście online oraz bloków danych[4]. W podejściu online pobiera się kolejno obiekty, które następnie zostają pojedynczo przetworzone przez wybrany algorytm. Z kolei w podejściu bloków danych pobiera się i przetwarza bloki danych składające się z wielu obiektów. W przypadku obu podejść istnieje wiele algorytmów, których zastosowanie zależy od typu analizowanych danych i sposobu nadzorowania uczenia[4]. Innym sposobem podziału metod klasyfikacji jest technika radzenia sobie z dryfem koncepcji. Wyróżnia się algorytmy oparte o detektor dryfu oraz metody zespołowe. Rozwiązania wykorzystujące detektor dryfu analizują jakość klasyfikatora, aby na podstawie tej metryki określić występowanie dryfu koncepcji i stworzyć nowy model klasyfikatora. Metody zespołowe bazują na uczeniu przyrostowym i polegają na stworzeniu określonej liczby klasyfikatorów w oparciu o dane uzyskane ze strumienia. Po stworzeniu odpowiedniej liczby klasyfikatorów stworzenie nowego z nowo pobranych danych skutkuje usunięciem najstarszego lub najgorszego modelu. Proces usunięcia nadmiarowego modelu nazywa się zapominaniem.
Algorytmy stosujące metodę detekcji dryfu monitorują jakość obecnego klasyfikatora poprzez obserwację skuteczności klasyfikatora, lub rozkładu znaczącej zmiennej strumienia w celu wykrycia dryfu koncepcji. W przypadku uczenia nadzorowanego do pierwszego podejścia zalicza się m.in. algorytmy Widmera i Kubata, DDM oraz EDDM, będący wariacją DDM, lecz wykorzystujący inne kryteria przy generowaniu sygnału ostrzegawczego[2]. Do detekcji dryfu koncepcji przy użyciu zmiennej strumienia wykorzystuje się głównie testy statystyczne porównujące dwa obserwowane bloki. Najczęściej wykorzystywanymi metodami statystycznymi są metody Welcha, Kolmogorova-Smirnova, test Page'a-Hinkley'a oraz MODL[2].
W przypadku uczenia nienadzorowanego rozwiązania dzieli się na metody online oraz metody bloków danych (ang. batch). Wśród metod bloków danych wyróżnia się metody detekcji pełnego oraz częściowego bloku danych. Z kolei do metod online zalicza się metody ze stałym blokiem porównawczym (ang. Fixed Reference Window) oraz ruchomym blokiem porównawczym (ang. Sliding Rederence Window)[5].
Metody zespołowe opierają się na decyzjach wielu klasyfikatorów, których pula w związku z naturą strumienia musi być stale aktualizowana poprzez tworzenie nowych klasyfikatorów w oparciu o nowe dane oraz zapominanie klasyfikatorów najstarszych lub ocenianych najgorzej. Nadzorowane zespołowe metody klasyfikacji strumieni można podzielić na metody stacjonarne oraz niestacjonarne, które dalej dzieli się na metody online oraz bloków danych. Wśród stacjonarnych metod online wyróżnia się algorytmy takie jak OzaBag, ASHT, czy ORF, z kolei do stacjonarnych metod opartych o bloki danych zalicza się algorytmy takie jak Learn++, Ada.Boost, Growing NCL, czy Bagging++. W przypadku metod niestacjonarnych pojawia się znacznie więcej proponowanych algorytmów, zarówno tych opierających się na podejściu online, jak i tych operujących na blokach danych. Do algorytmów online zalicza się podejścia pasywne takie jak DWM, AddExp i CDC oraz podejścia aktywne: ACE, Todi, DDD. Z kolei wśród najczęściej wykorzystywanych algorytmów operujących na blokach danych wymienia się SEA, AWE, Aboost oraz Learn++.NSE[4].

Uczenie aktywne
Celem uczenia aktywnego jest rozwiązanie problemu etykietowania danych przy uczeniu nadzorowanym. Kwestia uzbierania odpowiednio dużo danych, które są poprawnie wyetykietowanie jest często największym problemem podczas procesu uczenia. Dane co prawda łatwo znaleźć i to w dużych ilościach, problem jest z ich etykietowaniem. Jak podaje Settles etykietowanie takich danych jak nagranie ludzkiego głosu, etykietowanie dokumentów naukowych czy klasyfikacja dokumentów takich jak artykuły, czy strony internetowe wymaga wiele czasu jak i umiejętności od człowieka, aby je poprawnie oznaczyć. Uczenie aktywne pozwala na uzyskanie dobrych wyników korzystając ze zbiorów danych niewyetykietowanych. Algorytm wybiera kilka elementów z całego zbioru (zazwyczaj tych, do których obecnie najmniej jest pewny) i prosi człowieka o etykietowanie ich, nie prosząc o etykietowanie pozostałych danych, do których algorytm jest bardziej pewny klasyfikacji[6].
Wyróżnione są 3 scenariusze w jaki sposób algorytm uczący się w sposób aktywny może zadawać pytania. Pierwszym jest synteza zapytań o członkostwo. Uczeń może wysłać zapytanie o dowolny element ze zbioru uczącego, ale też wygenerować zapytanie do własnego przykładu w celu przypisania członkostwa do konkretnej klasy. Problemem bywa trudność przypisania przypadków niejasnych, gdy nie da się powiedzieć, do której klasy powinien dany element należeć.
Drugim scenariuszem jest selektywne próbkowanie oparte na strumieniu. W strumieniu problemem nie jest brak danych, a raczej ich nadmiar i uczeń musi szybko podjąć decyzję o stworzeniu zapytania. Jednak przy tym podejściu występują problemy niejednolitego rozkładu.
Trzecim scenariuszem jest próbkowanie danych w oparciu o pulę. Założeniem w tym scenariuszu jest fakt, że dane testowe będą pojawiać się w dużych grupach. Uczeń analizuje najpierw całą pulę danych a dopiero później wybiera, które dane powinny zostać wysłane jako zapytania. Ze względu na to, że wszystkie dane są analizowane równocześnie ten scenariusz wymaga sporych zasobów pamięciowych i obliczeniowych[6].
Pojawienie się uczenia aktywnego w strumieniach danych jest naturalną konsekwencją faktu, że danych na świecie przesyłanych jest coraz więcej i nie dałoby się ich wszystkich etykietować w odpowiednio krótkim czasie. Najbardziej wymagającym problemem przy uczeniu w oparciu o strumienie danych jest dryf koncepcyjny i skrzywienie danych[7]. Proponowaną strategią uczenia aktywnego dla klasyfikatora jest strategia MD-OAL[7], zaś w przypadku grupy klasyfikatorów algorytm dynamicznego wstrzymywania się od głosu[7]. Wskazane strategie dla uczenia w sposób online to strategia losowa i strategia stałej niepewności. W przypadku strategii losowej decyzja o wysłaniu zapytania jest stałą próbą losową, niezależną od żadnych metryk związanych z próbką. W przypadku strategii stałej niepewności zapytanie o etykietę wysyłane jest jeśli metryka niepewności jest poniżej jakiegoś stałego progu. Dla uczenia z wykorzystanie bloków danych używane są strategie zmiennej niepewności, oraz zmiennej niepewności z losowością. W przypadku strategii zmiennej losowości próg od którego wysyłane jest zapytanie jest zależny od wszystkich próbek w bloku, a przy strategii zmiennej niepewności z losowością wybór próbek, do których zostanie wysłane zapytanie wyznaczany jest na podstawie rozkładu normalnego, tak aby przede wszystkim były wybierane próbki o największej niepewności, ale czasami też te o większej[8]s.

Pozycje literaturowe:
1) Brzezinski, Dariusz & Stefanowski, Jerzy. (2016). Stream Clas-sification. 10.1007/978-1-4899-7502-7908-1.
2) Lemaire,  Vincent  &  Salperwyck,  Christophe  &  Bondu,  Alexis.(2015). A Survey on Supervised Classification on Data Streams.Lecture Notes in Business Information Processing. 10.1007/978-3-319-17551-54.
3) Gama, J.: Knowledge Discovery from Data Streams. Chapmanand Hall/CRC Press (2010)
4) Krawczyk, Bartosz & Minku, Leandro & Gama, Jo ̃ao & Stefa-nowski, Jerzy & Wozniak, Michal. (2017). Ensemble learning fordata stream analysis: A survey. Information Fusion. 37. 132–156.10.1016/j.inffus.2017.02.004.
5) Gemaque, R.N., Costa, A.F., Giusti, R., Santos, E. (2020). An overview of unsupervised drift detection methods. Wiley Interdi-sciplinary Reviews: Data Mining and Knowledge Discovery, 10.
6) Burr Settles. Active Learning Literature Survey. Computer Sciences  Technical  Report  1648,  University  of  Wisconsin–Madison.2009.
7) Łukasz  Korycki Alberto  Cano Bartosz  Krawczyk-Bartosz  Krawczyk  Active  Learning  with  Abstaining  Classifiers for Imbalanced Drifting Data Streams
8) Indrė Žliobaitė, Albert Bifet, Bernhard Pfahringer, Geoffrey Holmes Active Learning with Evolving Streaming Data
